{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_GPU = torch.cuda.device_count()\n",
    "print(\"Using {} GPUs\".format(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._homedir = \"..\"\n",
    "        \n",
    "        # Training Data path\n",
    "        self._datapath = os.path.join(\n",
    "            self._homedir, \n",
    "            kwargs.get(\"datapath\", \"hymenoptera_data\")\n",
    "        )\n",
    "        self._target_classes = ['ants', 'bees']\n",
    "        self._target_class_to_idx = {\n",
    "            \"ants\": 0,\n",
    "            \"bees\": 1\n",
    "        }\n",
    "        \n",
    "        # Model backbone\n",
    "        self._model_backbone = \"resnet18\"\n",
    "        self._pretrain = True\n",
    "\n",
    "        # Data Loader configs\n",
    "        self._batch_size = kwargs.get(\"batch_size\", 16)\n",
    "        self._shuffle = kwargs.get(\"shuffle\", True)\n",
    "        self._num_worker = kwargs.get(\"num_worker\", 0)\n",
    "\n",
    "        # Optimization params\n",
    "        self._num_epochs = kwargs.get(\"num_epochs\", 25)\n",
    "        self._learning_rate = kwargs.get(\"learning_rate\", 0.001)\n",
    "        self._momentum = kwargs.get(\"momentum\", 0.9)\n",
    "        self._lr_scheduler_dict = kwargs.get(\"lr_scheduler\", {\n",
    "            \"__name__\": \"step_lr\",\n",
    "            \"step_size\": 7,\n",
    "            \"gamma\": 0.1\n",
    "        })\n",
    "        \n",
    "        # Output file\n",
    "        self._snapshot_folder = os.path.join(\n",
    "            self._homedir,\n",
    "            kwargs.get(\"snapshot_folder\", \"snapshots\")\n",
    "        )\n",
    "        self._results_folder = os.path.join(\n",
    "            self._homedir,\n",
    "            kwargs.get(\"result_folder\", \"results\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneModel(Config):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_model(self, num_labels):\n",
    "        if self._model_backbone == \"resnet18\":\n",
    "            model_ft = models.resnet18(pretrained=self._pretrain)\n",
    "            num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "            model_ft.fc = nn.Linear(num_ftrs, num_labels)\n",
    "\n",
    "            return model_ft\n",
    "        \n",
    "    def _num_total_params(self, _model):\n",
    "        num_params = 0\n",
    "        \n",
    "        for p in _model.parameters():\n",
    "            num_params += p.numel()\n",
    "            \n",
    "        return num_params\n",
    "    \n",
    "    def _num_trainable_params(self, _model):\n",
    "        return sum(p.numel() for p in _model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassification(Config):\n",
    "    def __init__(self, weight_path, gpu_number=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # prepare model\n",
    "        self._load_model_weights(weight_path)\n",
    "            \n",
    "    def _preprocess_data(self, image_path):\n",
    "        inference_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        image_ = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        image_tensor = inference_transforms(image_).float().unsqueeze_(0)\n",
    "    \n",
    "        return image_tensor\n",
    "    \n",
    "    def _process_output(self, image_tensor):\n",
    "        input_ = image_tensor.to(DEVICE)\n",
    "        output_ = self.model(input_)\n",
    "        \n",
    "        raw_output = [\n",
    "            np.round(v, 4) \n",
    "            for v in output_.data.cpu().numpy().tolist()[0]\n",
    "        ]\n",
    "        \n",
    "        _, preds = torch.max(output_, 1)\n",
    "        \n",
    "        pred_index = preds.data.cpu().numpy()[0]\n",
    "        \n",
    "        pred_class = [\n",
    "            k \n",
    "            for k, v in self._target_class_to_idx.items()\n",
    "            if v == pred_index \n",
    "        ][0]\n",
    "        \n",
    "        return {\n",
    "            \"predicted_class\": pred_class,\n",
    "            \"raw_output\": raw_output,\n",
    "            \"predicted_label\": pred_index\n",
    "        }\n",
    "\n",
    "    def _load_model_weights(self, weight_path):\n",
    "        print(\"Preparing model: {} ...\".format(self._model_backbone))\n",
    "        self.model = FineTuneModel().get_model(len(self._target_classes))\n",
    "        \n",
    "        print(\"Preparing model: mapping to devices...\")\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "        self.model.to(DEVICE)\n",
    "        \n",
    "        print(\"Loading weights: {} ...\".format(weight_path))  \n",
    "        checkpoint = torch.load(weight_path, map_location=DEVICE)\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        self.model.to(DEVICE)\n",
    "        \n",
    "        print(\"Model is ready!\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "            \n",
    "    def predict(self, image_path):\n",
    "        image_tensor_ = self._preprocess_data(image_path)\n",
    "        output_ = self._process_output(image_tensor_)\n",
    "        \n",
    "        output_.update({\"image_path\": image_path})\n",
    "        \n",
    "        return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model: resnet18 ...\n",
      "Preparing model: mapping to devices...\n",
      "Loading weights: ../results/best_resnet18_acc0.9477_checkpoint.pth.tar ...\n",
      "Model is ready!\n",
      "{'predicted_class': 'bees', 'raw_output': [-1.4259, 1.0546], 'predicted_label': 1, 'image_path': '../hymenoptera_data/val/bees/144098310_a4176fd54d.jpg'}\n",
      "{'predicted_class': 'bees', 'raw_output': [-2.235, 1.5869], 'predicted_label': 1, 'image_path': '../hymenoptera_data/val/bees/2841437312_789699c740.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.4502, -1.6709], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/8124241_36b290d372.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [2.0823, -2.0385], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/F.pergan.28(f).jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.1002, -1.448], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/bees/54736755_c057723f64.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [0.2554, 0.248], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/8398478_50ef10c47a.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.0859, -1.364], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/161292361_c16e0bf57a.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.1445, -0.9652], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/436944325_d4925a38c7.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [0.8058, -0.7107], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/bees/2709775832_85b4b50a57.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [2.2211, -2.4559], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/35558229_1fa4608a7a.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.5517, -2.5484], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/1262751255_c56c042b7b.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [2.4842, -2.5637], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/2219621907_47bc7cc6b0.jpg'}\n",
      "{'predicted_class': 'bees', 'raw_output': [-2.1448, 2.8782], 'predicted_label': 1, 'image_path': '../hymenoptera_data/val/bees/2478216347_535c8fe6d7.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.4787, -1.9805], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/1440002809_b268d9a66a.jpg'}\n",
      "{'predicted_class': 'bees', 'raw_output': [-1.7318, 2.1953], 'predicted_label': 1, 'image_path': '../hymenoptera_data/val/bees/2103637821_8d26ee6b90.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.5517, -2.5484], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/1262751255_c56c042b7b.jpg'}\n",
      "{'predicted_class': 'bees', 'raw_output': [-2.3835, 2.5813], 'predicted_label': 1, 'image_path': '../hymenoptera_data/val/bees/187130242_4593a4c610.jpg'}\n",
      "{'predicted_class': 'bees', 'raw_output': [-2.3763, 2.4895], 'predicted_label': 1, 'image_path': '../hymenoptera_data/val/bees/215512424_687e1e0821.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [1.0052, -1.2876], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/181942028_961261ef48.jpg'}\n",
      "{'predicted_class': 'ants', 'raw_output': [0.2767, -0.2534], 'predicted_label': 0, 'image_path': '../hymenoptera_data/val/ants/319494379_648fb5a1c6.jpg'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "c = ImageClassification(weight_path=\"../results/best_resnet18_acc0.9477_checkpoint.pth.tar\", gpu_number=[6])\n",
    "for f in random.choices(glob.glob(\"../hymenoptera_data/val/*/*\"), k=20):\n",
    "    print(c.predict(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
