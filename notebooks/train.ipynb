{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_GPU = torch.cuda.device_count()\n",
    "print(\"Using {} GPUs\".format(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._homedir = \"..\"\n",
    "        \n",
    "        # Training Data path\n",
    "        self._datapath = os.path.join(\n",
    "            self._homedir, \n",
    "            kwargs.get(\"datapath\", \"hymenoptera_data\")\n",
    "        )\n",
    "        self._target_classes = ['ants', 'bees']\n",
    "        self._target_class_to_idx = {\n",
    "            \"ants\": 0,\n",
    "            \"bees\": 1\n",
    "        }\n",
    "        \n",
    "        # Model backbone\n",
    "        self._model_backbone = \"resnet18\"\n",
    "        self._pretrain = True\n",
    "\n",
    "        # Data Loader configs\n",
    "        self._batch_size = kwargs.get(\"batch_size\", 16)\n",
    "        self._shuffle = kwargs.get(\"shuffle\", True)\n",
    "        self._num_worker = kwargs.get(\"num_worker\", 0)\n",
    "\n",
    "        # Optimization params\n",
    "        self._num_epochs = kwargs.get(\"num_epochs\", 25)\n",
    "        self._learning_rate = kwargs.get(\"learning_rate\", 0.001)\n",
    "        self._momentum = kwargs.get(\"momentum\", 0.9)\n",
    "        self._lr_scheduler_dict = kwargs.get(\"lr_scheduler\", {\n",
    "            \"__name__\": \"step_lr\",\n",
    "            \"step_size\": 7,\n",
    "            \"gamma\": 0.1\n",
    "        })\n",
    "        \n",
    "        # Output file\n",
    "        self._snapshot_folder = os.path.join(\n",
    "            self._homedir,\n",
    "            kwargs.get(\"snapshot_folder\", \"snapshots\")\n",
    "        )\n",
    "        self._results_folder = os.path.join(\n",
    "            self._homedir,\n",
    "            kwargs.get(\"result_folder\", \"results\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneModel(Config):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_model(self, num_labels):\n",
    "        if self._model_backbone == \"resnet18\":\n",
    "            model_ft = models.resnet18(pretrained=self._pretrain)\n",
    "            num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "            model_ft.fc = nn.Linear(num_ftrs, num_labels)\n",
    "\n",
    "            return model_ft\n",
    "        \n",
    "    def _num_total_params(self, _model):\n",
    "        num_params = 0\n",
    "        \n",
    "        for p in _model.parameters():\n",
    "            num_params += p.numel()\n",
    "            \n",
    "        return num_params\n",
    "    \n",
    "    def _num_trainable_params(self, _model):\n",
    "        return sum(p.numel() for p in _model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTDataset(Config, Dataset):\n",
    "    def __init__(self, phase=\"train\", **kwargs):\n",
    "        # intialize config\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # current phase\n",
    "        self._phase = phase\n",
    "        \n",
    "        # load raw data\n",
    "        self._prepare_data()\n",
    "\n",
    "    _image_transforms = None\n",
    "    @property\n",
    "    def image_transforms(self):\n",
    "        if self._image_transforms is None:\n",
    "            self._image_transforms = self._set_image_transforms()\n",
    "        return self._image_transforms\n",
    "\n",
    "    @image_transforms.setter\n",
    "    def image_transforms(self, image_transforms):\n",
    "        self._image_transforms = image_transforms\n",
    "\n",
    "    def _set_image_transforms(self):\n",
    "        \"\"\"Function to set up data augmentation\n",
    "        \n",
    "        Data augmentation and normalization for training; just normalization for validation\n",
    "        \"\"\"\n",
    "        if self._phase == \"train\":\n",
    "            return transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        elif self._phase == \"val\":\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    @property\n",
    "    def data_location(self):\n",
    "        return os.path.join(self._datapath, self._phase)\n",
    "    \n",
    "    def _prepare_data(self):\n",
    "        \"\"\"Function to load data from raw images with targets\n",
    "        \n",
    "        Attributes:\n",
    "            image_labels: [\n",
    "                                (image_path_1, target_1), \n",
    "                                (image_path_2, target_2),\n",
    "                                ...\n",
    "                          ]\n",
    "        \"\"\"\n",
    "        self.image_labels = [\n",
    "            (f, os.path.basename(os.path.dirname(f)))\n",
    "            for f in glob.glob(os.path.join(self.data_location, \"*\", \"*\"))\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename, target = self.image_labels[idx]\n",
    "        \n",
    "        img = Image.open(filename).convert('RGB')\n",
    "        img_ = self.image_transforms(img)\n",
    "        \n",
    "        label_ = self._target_class_to_idx[target]\n",
    "\n",
    "        return img_, label_\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_labels)\n",
    "\n",
    "class FTDataLoader(Config):\n",
    "    def __init__(self, phase=\"train\", **kwargs):\n",
    "        # intialize config\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # current phase\n",
    "        self._phase = phase\n",
    "        self.image_dataset = FTDataset(phase=phase, **kwargs)\n",
    "        \n",
    "        # set global batch size (for multi-device training)\n",
    "        self._global_batch_size = kwargs.get(\"global_batch_size\", self._batch_size)\n",
    "\n",
    "    _dataloader = None\n",
    "    @property\n",
    "    def dataloader(self):\n",
    "        if self._dataloader is None:\n",
    "            self._dataloader = self._get_data_loader()\n",
    "        return self._dataloader\n",
    "\n",
    "    @dataloader.setter\n",
    "    def dataloader(self, dataloader):\n",
    "        self._dataloader = dataloader\n",
    "        \n",
    "    def _get_data_loader(self):\n",
    "        return DataLoader(\n",
    "            self.image_dataset, \n",
    "            batch_size=self._global_batch_size,\n",
    "            shuffle=self._shuffle, \n",
    "            num_workers=self._num_worker\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _size(self):\n",
    "        return len(self.image_dataset)\n",
    "\n",
    "    @property\n",
    "    def _classes(self):\n",
    "        return self.image_dataset._target_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(Config):\n",
    "    def __init__(self, gpu_number=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # prepare data\n",
    "        self._get_dataset()\n",
    "        \n",
    "        # prepare model\n",
    "        self._get_or_load_model()\n",
    "        self._set_optimizer(self.model.parameters())\n",
    "        self._set_criterion()\n",
    "        self._set_learningrate_scheduler()\n",
    "\n",
    "    def _get_dataset(self):\n",
    "        for p in [\"train\", \"val\"]:\n",
    "            temp_d = FTDataLoader(phase=p, global_batch_size=NUM_GPU * self._batch_size)\n",
    "            setattr(self, \"{}_dataloader\".format(p), temp_d.dataloader)\n",
    "            setattr(self, \"{}_datasize\".format(p), temp_d._size)\n",
    "\n",
    "    def _get_or_load_model(self):\n",
    "        self.model = FineTuneModel().get_model(len(self._target_classes))\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "    def _set_optimizer(self, parameters):\n",
    "        self.optimizer = optim.SGD(\n",
    "            parameters,\n",
    "            lr=self._learning_rate,\n",
    "            momentum=self._momentum,\n",
    "        )\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def _set_learningrate_scheduler(self):\n",
    "        if self._lr_scheduler_dict[\"__name__\"] == \"step_lr\":\n",
    "            self.lr_scheduler = lr_scheduler.StepLR(\n",
    "                self.optimizer, \n",
    "                step_size=self._lr_scheduler_dict.get(\"step_size\", 7), \n",
    "                gamma=self._lr_scheduler_dict.get(\"gamma\", 0.1)\n",
    "            )\n",
    "            \n",
    "    def save_checkpoint(self, state, epoch, filename='checkpoint.pth.tar'):\n",
    "        if not os.path.exists(self._snapshot_folder):\n",
    "            os.makedirs(self._snapshot_folder)\n",
    "        \n",
    "        absolute_path = os.path.join(self._snapshot_folder, \"epoch_{}_{}\".format(epoch, filename))\n",
    "        torch.save(state, absolute_path)\n",
    "        \n",
    "    def update_best_model(self, epoch, acc, filename='checkpoint.pth.tar'):\n",
    "        if not os.path.exists(self._results_folder):\n",
    "            os.makedirs(self._results_folder)\n",
    "        \n",
    "        current_absolute_path = os.path.join(self._snapshot_folder, \"epoch_{}_{}\".format(epoch, filename))\n",
    "        best_absolute_path = os.path.join(self._snapshot_folder, \"best_{}\".format(filename))\n",
    "        best_absolute_result = os.path.join(\n",
    "            self._results_folder, \n",
    "            \"best_{}_acc{:.4f}_{}\".format(self._model_backbone, acc, filename)\n",
    "        )\n",
    "        \n",
    "        shutil.copyfile(current_absolute_path, best_absolute_path)\n",
    "        shutil.copyfile(current_absolute_path, best_absolute_result)\n",
    "        print(\"Saving new best model to results: {}\".format(best_absolute_result))\n",
    "        \n",
    "    def restore_model(self, resultname=None, epoch=-1, filename='checkpoint.pth.tar'):\n",
    "        if resultname is None:\n",
    "            if epoch == -1:\n",
    "                model_path = \"best_{}\".format(filename)\n",
    "            else:\n",
    "                model_path = \"epoch_{}_{}\".format(epoch, filename)\n",
    "\n",
    "            model_fullpath = os.path.join(self._snapshot_folder, model_path)\n",
    "        else:\n",
    "            model_fullpath = os.path.join(self._results_folder, resultname)\n",
    "        \n",
    "        print(\"Loading model: {}\".format(model_fullpath))\n",
    "        checkpoint = torch.load(model_fullpath, map_location=DEVICE)\n",
    "        self.model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "    def train(self, load_epoch=None, load_model=None):\n",
    "        print('Start training...')\n",
    "        since_ = time.time()\n",
    "\n",
    "        if load_model is not None:\n",
    "            self.restore_model(resultname=load_model)\n",
    "        elif load_epoch is not None:\n",
    "            self.restore_model(epoch=load_epoch)\n",
    "            \n",
    "        best_epoch = 0\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(self._num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self._num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "            \n",
    "            loss_dict = {}\n",
    "            acc_dict = {}\n",
    "            \n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    self.model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    self.model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in getattr(self, \"{}_dataloader\".format(phase)):\n",
    "                    # map data to device\n",
    "                    inputs = inputs.to(DEVICE)\n",
    "                    labels = labels.to(DEVICE)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    # clears old gradients from the last step \n",
    "                    # (otherwise you’d just accumulate the gradients from all loss.backward() calls).\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    # set_grad_enabled() can be used to conditionally enable gradients.\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = self.model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = self.criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            # computes the derivative of the loss w.r.t. the parameters\n",
    "                            # (or anything requiring gradients) using backpropagation.\n",
    "                            loss.backward()\n",
    "                            \n",
    "                            # Performs a single optimization step (parameter update).\n",
    "                            self.optimizer.step() \n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # learning rate update for training only\n",
    "                if phase == 'train':\n",
    "                    # update learning rate with learning rate scheduler\n",
    "                    self.lr_scheduler.step()\n",
    "\n",
    "                # save stats and display\n",
    "                epoch_loss = running_loss / getattr(\n",
    "                    self, \"{}_datasize\".format(phase)\n",
    "                )\n",
    "                loss_dict[phase] = epoch_loss\n",
    "                \n",
    "                epoch_acc = running_corrects.double() / getattr(\n",
    "                    self, \"{}_datasize\".format(phase)\n",
    "                )\n",
    "                acc_dict[phase] = epoch_acc\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc\n",
    "                ))\n",
    "                \n",
    "                # save intermediate model state, params and etc.\n",
    "                if phase == 'val':\n",
    "                    self.save_checkpoint(\n",
    "                        {\n",
    "                            'lr': self.optimizer.param_groups[0][\"lr\"],\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'loss_stats': loss_dict,\n",
    "                            'acc_stats': acc_dict\n",
    "                        },\n",
    "                        epoch\n",
    "                    )\n",
    "\n",
    "                    # deep copy the model\n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                        best_epoch = epoch\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        self.update_best_model(best_epoch, best_acc)\n",
    "        \n",
    "        time_elapsed = time.time() - since_\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        \n",
    "    def evaluate(self, epoch):\n",
    "        # load model\n",
    "        self.restore_model(epoch)\n",
    "        \n",
    "        # Set model to evaluate mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "            \n",
    "        for inputs, labels in self.val_dataloader:\n",
    "            # map data to device\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        total_loss = running_loss / self.val_datasize\n",
    "        total_acc = running_corrects / self.val_datasize\n",
    "            \n",
    "        print(\"Total Loss: {:.4f}, Acc: {:.4f}\".format(total_loss, total_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Loading model: ../results/best_resnet18_acc0.9477_checkpoint.pth.tar\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9306\n",
      "val Loss: 0.1886 Acc: 0.9477\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.1801 Acc: 0.9510\n",
      "val Loss: 0.1939 Acc: 0.9477\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.1854 Acc: 0.9469\n",
      "val Loss: 0.1898 Acc: 0.9477\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.1706 Acc: 0.9347\n",
      "val Loss: 0.1878 Acc: 0.9412\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1660 Acc: 0.9469\n",
      "val Loss: 0.1917 Acc: 0.9412\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1499 Acc: 0.9469\n",
      "val Loss: 0.1856 Acc: 0.9477\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1770 Acc: 0.9429\n",
      "val Loss: 0.1859 Acc: 0.9477\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.1674 Acc: 0.9265\n",
      "val Loss: 0.1839 Acc: 0.9412\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1778 Acc: 0.9429\n",
      "val Loss: 0.1833 Acc: 0.9477\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1810 Acc: 0.9306\n",
      "val Loss: 0.1803 Acc: 0.9412\n",
      "Saving new best model to results: ../results/best_resnet18_acc0.9477_checkpoint.pth.tar\n",
      "Training complete in 0m 36s\n",
      "Best val Acc: 0.947712\n"
     ]
    }
   ],
   "source": [
    "s = Solver(num_epochs=10, gpu_number=[6], lr_scheduler={\n",
    "            \"__name__\": \"step_lr\",\n",
    "            \"step_size\": 1,\n",
    "            \"gamma\": 0.1\n",
    "        })\n",
    "s.train(load_model=\"best_resnet18_acc0.9477_checkpoint.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
